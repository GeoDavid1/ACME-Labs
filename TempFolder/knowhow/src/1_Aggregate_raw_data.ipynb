{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Use functions from the tools module\n",
    "from tools import recursive_cum_avg, calculate_bmi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset data for relevant participants and intake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1628 1138 490\n",
      "1628 1410 218\n"
     ]
    }
   ],
   "source": [
    "#Blood subset\n",
    "\n",
    "df2 = pd.read_excel('../data/raw_data/outcomes_reformatted.xlsx')\n",
    "all_participants = len(df2['participant_id'].unique())\n",
    "df2.dropna(subset=['ecid_ldl'], inplace=True)\n",
    "participant_ids = df2['participant_id'].value_counts()\n",
    "df2['largest_ecid_cid_date'] = df2.groupby('participant_id')['ecid_cid_date'].transform('max')\n",
    "participants_with_blood_follow_up =  participant_ids[participant_ids == 2].index.tolist()\n",
    "participants_with_blood_follow_up_dict = {}\n",
    "for id in participants_with_blood_follow_up:\n",
    "    participants_with_blood_follow_up_dict[id] = df2[df2['participant_id']==id]['largest_ecid_cid_date'].values[0]\n",
    "\n",
    "print(all_participants, len(participants_with_blood_follow_up_dict), all_participants - len(participants_with_blood_follow_up_dict))\n",
    "\n",
    "#Anthro subset\n",
    "df2 = pd.read_excel('../data/raw_data/outcomes_reformatted.xlsx')\n",
    "all_participants = len(df2['participant_id'].unique())\n",
    "df2.dropna(subset=['ecid_waist'], inplace=True)\n",
    "participant_ids = df2['participant_id'].value_counts()\n",
    "df2['largest_ecid_cid_date'] = df2.groupby('participant_id')['ecid_cid_date'].transform('max')\n",
    "participants_with_anthro_follow_up =  participant_ids[participant_ids > 1 ].index.tolist()\n",
    "participants_with_anthro_follow_up_dict = {}\n",
    "for id in participants_with_anthro_follow_up:\n",
    "    participants_with_anthro_follow_up_dict[id] = df2[df2['participant_id']==id]['largest_ecid_cid_date'].values[0]\n",
    "\n",
    "print(all_participants, len(participants_with_anthro_follow_up_dict), all_participants - len(participants_with_anthro_follow_up_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1: Preprocess the Dietary Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module 1: Preprocess the dietary data\n",
    "blood = False\n",
    "\n",
    "# Read in the nutritional intake data\n",
    "df = pd.read_excel('../data/raw_data/Aggregated_by_IR_id_dailyintake.xlsx')\n",
    "\n",
    "# Need to only retain the participants and intake rows of interest. \n",
    "if blood:\n",
    "    #drop all participants not in participants_with_blood_follow_up_dict\n",
    "    df = df[df['Participant_ID'].isin(participants_with_blood_follow_up_dict.keys())]\n",
    "\n",
    "    #drop all rows for every participant for which date is greater than value in participants_with_blood_follow_up_dict\n",
    "    df['largest_ecid_cid_date'] = df['Participant_ID'].map(participants_with_blood_follow_up_dict)\n",
    "    df = df[df['intake_response_date'] <= df['largest_ecid_cid_date']]\n",
    "    df.drop(columns=['largest_ecid_cid_date'], inplace=True)\n",
    "else:\n",
    "    #drop all participants not in participants_with_anthro_follow_up_dict\n",
    "    df = df[df['Participant_ID'].isin(participants_with_anthro_follow_up_dict.keys())]\n",
    "\n",
    "    #drop all rows for every participant for which date is greater than value in participants_with_anthro_follow_up_dict\n",
    "    df['largest_ecid_cid_date'] = df['Participant_ID'].map(participants_with_anthro_follow_up_dict)\n",
    "    df = df[df['intake_response_date'] <= df['largest_ecid_cid_date']]\n",
    "    df.drop(columns=['largest_ecid_cid_date'], inplace=True)\n",
    "\n",
    "# Pull out from the aggregation data the participant ID and CID columns\n",
    "aggregation_dict = {\n",
    "    'Participant_ID': 'first',\n",
    "    'CID': 'first'}\n",
    "\n",
    "#Create a list of column names not present in aggregation_dict, excluding the first two columns\n",
    "summed_cols = [col for col in df.columns if col not in aggregation_dict.keys()][2:]\n",
    "\n",
    "# Step 1: Sum up by 'intake_response_id', # Not really necessary - as there are only unique values\n",
    "for col in summed_cols:\n",
    "    # Update aggregation_dict with the column name and the sum function\n",
    "    aggregation_dict[col] = 'sum'\n",
    "\n",
    "aggregated_df = df.groupby(['intake_response_id']).agg(aggregation_dict).reset_index()\n",
    "\n",
    "# Step 2: Second aggregation calculates the averages per CID\n",
    "aggregation_dict = {}\n",
    "for col in summed_cols:\n",
    "    aggregation_dict[col] = 'mean'\n",
    "    \n",
    "aggregated_df = aggregated_df.groupby(['Participant_ID','CID']).agg(aggregation_dict).reset_index()\n",
    "\n",
    "# Step 3: Third aggregation calculates the cumulative averages per CID\n",
    "aggregation_dict = {}\n",
    "for col in summed_cols:\n",
    "    aggregation_dict[col] = recursive_cum_avg\n",
    "\n",
    "#BEWARE: at times a single variable was not measured and entered as zero! For those we calculate the cum avg everywhere else!\n",
    "aggregated_df = aggregated_df.groupby(['Participant_ID']).agg(aggregation_dict).reset_index()\n",
    "\n",
    "#Now we need to create new variables for intake_carbohydrates.\n",
    "aggregated_df['intake_carbohydrate-intake_total_sugars'] = aggregated_df['intake_carbohydrate'] - aggregated_df['intake_total_sugars']\n",
    "aggregated_df['intake_carbohydrate-intake_nmes'] = aggregated_df['intake_carbohydrate'] - aggregated_df['intake_nmes']\n",
    "aggregated_df['intake_carbohydrate-intake_intrinsic_sugars'] = aggregated_df['intake_carbohydrate'] - aggregated_df['intake_intrinsic_sugars']\n",
    "aggregated_df['intake_carbohydrate-intake_fructose'] = aggregated_df['intake_carbohydrate'] - aggregated_df['intake_fructose']\n",
    "aggregated_df['intake_carbohydrate-intake_glucose'] = aggregated_df['intake_carbohydrate'] - aggregated_df['intake_glucose']\n",
    "\n",
    "#Convert to megajoules\n",
    "aggregated_df['intake_energy_mj'] = aggregated_df['intake_energy_kj'] / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2: Preprocess the Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the outcomes data\n",
    "df2 = pd.read_excel('../data/raw_data/outcomes_reformatted.xlsx')\n",
    "\n",
    "if blood:\n",
    "    #drop all participants not in participants_with_blood_follow_up_dict\n",
    "    df2 = df2[df2['participant_id'].isin(participants_with_blood_follow_up_dict.keys())]\n",
    "else:\n",
    "    #drop all participants not in participants_with_anthro_follow_up_dict\n",
    "    df2 = df2[df2['participant_id'].isin(participants_with_anthro_follow_up_dict.keys())]\n",
    "\n",
    "# Iterate through columns\n",
    "for col in df2.columns:\n",
    "    # Check if the column name ends with '.1'\n",
    "    if col.endswith('.1'):\n",
    "        # Extract the original column name\n",
    "        original_col = col[:-2]\n",
    "        # Fill missing values in the original column with values from the '.1' column\n",
    "        df2[original_col] = df2[col].fillna(df2[original_col])\n",
    "\n",
    "# List of needed columns for preprocessing of outcomes\n",
    "needed_cols = [\n",
    "    'participant_id', \n",
    "    'ecid_cid_date',\n",
    "    'CID',\n",
    "    'centre_id', \n",
    "    'study_arm_id',\n",
    "    'has_withdrawn', \n",
    "    'ecid_diabetes_1',\n",
    "    'ecid_weight_recorded',\n",
    "    'ecid_height_recorded',\n",
    "    'ecid_ldl',\n",
    "    'ecid_hdl',\n",
    "    'ecid_trig',\n",
    "    'ecid_hba1c_mmol_mol',\n",
    "    'ecid_hba1c_percent',\n",
    "    'cid_moissl_fat_mass',\n",
    "    'cid_moissl_fat_mass_percent',\n",
    "    'elig_age',\n",
    "    'elig_gender',\n",
    "    'ecid_waist']\n",
    "\n",
    "# Select only the needed columns for the DataFrame\n",
    "df2 = df2[needed_cols]\n",
    "\n",
    "# Define the aggregation dictionary\n",
    "aggregation_dict = {\n",
    "    'centre_id':'first', \n",
    "    'study_arm_id':'first',\n",
    "    'has_withdrawn':'first', \n",
    "    'ecid_diabetes_1':'max',\n",
    "    'ecid_weight_recorded':recursive_cum_avg,\n",
    "    'ecid_height_recorded':'max',\n",
    "    'ecid_ldl':recursive_cum_avg,\n",
    "    'ecid_hdl':recursive_cum_avg,\n",
    "    'ecid_trig':recursive_cum_avg,\n",
    "    'ecid_hba1c_mmol_mol':recursive_cum_avg,\n",
    "    'ecid_hba1c_percent':recursive_cum_avg,\n",
    "    'cid_moissl_fat_mass':recursive_cum_avg,\n",
    "    'cid_moissl_fat_mass_percent':recursive_cum_avg,\n",
    "    'elig_age':'max',\n",
    "    'elig_gender':'max',\n",
    "    'ecid_waist':recursive_cum_avg\n",
    "}\n",
    "\n",
    "# Perform aggregation by group on 'participant_id' and reset the index\n",
    "aggregated_df2 = df2.groupby(['participant_id']).agg(aggregation_dict).reset_index()\n",
    "\n",
    "# Calculate BMI\n",
    "aggregated_df2['bmi'] = aggregated_df2.apply(lambda row: calculate_bmi(row['ecid_weight_recorded'], row['ecid_height_recorded']), axis=1)\n",
    "\n",
    "# Make new column names                                                                              \n",
    "new_column_names = ['Participant_ID', 'centre_id', 'study_arm_id', 'has_withdrawn', 'diabetes', 'weight', 'height', 'ldl',\n",
    "       'hdl', 'trig', 'hba1c', 'hba1c_percent', 'bodyfat', 'bodyfat_percent', 'age', 'gender', 'waistcirumference',\n",
    "       'bmi']\n",
    "\n",
    "# All missing values should be replaced with NaN\n",
    "aggregated_df2.replace(0, float('nan'), inplace=True)\n",
    "\n",
    "# Rename the different columns\n",
    "aggregated_df2.rename(columns=dict(zip(aggregated_df2.columns, new_column_names)), inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3 - Combine the Two Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(aggregated_df, aggregated_df2, on='Participant_ID')\n",
    "if blood:\n",
    "    merged_df.to_excel('../data/processed_files/aggregrated_data_blood.xlsx', index=False)\n",
    "else:\n",
    "    merged_df.to_excel('../data/processed_files/aggregrated_data_anthro.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zontal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
